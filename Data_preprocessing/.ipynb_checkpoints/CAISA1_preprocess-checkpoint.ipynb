{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CASIA_1 Dataset Groundtruth Mask\n",
    "<font size=3>There is no ground-truth mask in CASIA dataset. We subtract the real image from the manipulated image to generate the ground-truth mask. Median blur is used to eliminate noise.<br>\n",
    "    \n",
    "The original link to the dataset is no longer available. We obtain the dataset from the [link](https://www.kaggle.com/sophatvathana/casia-dataset).<br>\n",
    "Based on this script, you can generate the groundtruth mask and test set text files for CASIA-1.<br><br>\n",
    "\n",
    "Please note that we set some thresholds in the script, which may cause some images in the dataset to be ignored, you can process these images separately.<br><br>\n",
    "We only provide the CASIA-1 script, you can modify it to preprocess the CASIA-2 dataset.<font>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage.color as color\n",
    "import skimage.io as io\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "casia_dir = '../dataset/casia/CASIA1/'\n",
    "sp_dir = casia_dir+'Sp/'        # Tampered images path\n",
    "mask_dir = '../dataset/casia/mask/'    # Mask path\n",
    "probe_dir = '../dataset/casia/probe/'   # Probe path\n",
    "au_dir = casia_dir+'/Au'        # Authentic images path\n",
    "ext = 'Sp*'\n",
    "dataType = '.jpg'\n",
    "\n",
    "# Create data storage path\n",
    "if not os.path.exists(mask_dir):\n",
    "  os.makedirs(mask_dir)\n",
    "\n",
    "if not os.path.exists(probe_dir):\n",
    "  os.makedirs(probe_dir)\n",
    "filenames = glob(os.path.join(sp_dir, ext))   # All tampered images list\n",
    "im_num = len(filenames)\n",
    "im_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bounding box label from groundtruth mask\n",
    "def bounding_box(image,mask,row_data):\n",
    "    box_list=[]\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    print(\"contours num：\", len(contours))\n",
    "    image_copy=image.copy()\n",
    "    contours = sorted(contours, key=lambda i: len(i),reverse=True)\n",
    "    for i in range(0, len(contours)):\n",
    "        area=cv2.contourArea(contours[i])\n",
    "        print(area,mask.shape[0]/20*image.shape[1]/20)\n",
    "        if area>(mask.shape[0]/20*image.shape[1]/20):\n",
    "            print(i)\n",
    "            x, y, w, h = cv2.boundingRect(contours[i])\n",
    "            x1=x\n",
    "            y1=y\n",
    "            x2=x+w\n",
    "            y2=y+h\n",
    "            box_list.append(str(x1)+'_'+str(y1)+'_'+ str(x2)+'_'+str(y2))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if len(box_list)==0 and len(contours)!=0:\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        x1 = x\n",
    "        y1 = y\n",
    "        x2 = x + w\n",
    "        y2 = y + h\n",
    "        box_list.append(str(x1) + '_' + str(y1) + '_' + str(x2) + '_' + str(y2))\n",
    "    if len(contours)==0 and len(box_list)==0 :\n",
    "        box_list.append('0' + '_' + '0' + '_' + '0' + '_' + '0')\n",
    "    return box_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 images     Tp_pla0005_pla0023_A0281_113_87_253_177_tamper\n"
     ]
    }
   ],
   "source": [
    "# Generate CASIA mask\n",
    "test_name=[]\n",
    "cls='tamper'\n",
    "for im in filenames:\n",
    "    \n",
    "    img_org = io.imread(im)\n",
    "    img = img_org.copy()\n",
    "    img_org = cv2.cvtColor(img_org, cv2.COLOR_RGB2BGR)\n",
    "    base_name = os.path.splitext(os.path.basename(im))[0]\n",
    "    content = base_name.split(\"_\")\n",
    "    au_tmp = str(content[4])\n",
    "    auth_name = 'Au_' + au_tmp[:-4] + '_' + au_tmp[-4:] + '*'#Authentic image name\n",
    "\n",
    "    auth_img = io.imread(glob(os.path.join(au_dir, auth_name))[0])\n",
    "    if (img.shape != auth_img.shape):\n",
    "        au_tmp = str(content[5])\n",
    "        auth_name = 'Au_' + au_tmp[:-4] + '_' + au_tmp[-4:] + '*'\n",
    "        auth_img = io.imread(glob(os.path.join(au_Dir, auth_name))[0])\n",
    "    img = color.rgb2grey(img)\n",
    "    auth_img = color.rgb2grey(auth_img)\n",
    "    \n",
    "    # Generate coarse mask\n",
    "    mask = np.abs(img - auth_img) * 255\n",
    "    # Eliminate noise\n",
    "    ret, mask = cv2.threshold(mask, 15, 255, cv2.THRESH_BINARY)#After testing, the threshold is set to 15\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask = cv2.medianBlur(mask, 5)#Remove noise\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)#Binarization\n",
    "\n",
    "    # Generate a new mask that contains only large regions\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = sorted(contours, key=lambda i: len(i), reverse=True)\n",
    "    mask_save = np.zeros_like(mask, dtype=np.uint8)\n",
    "    c_max = []\n",
    "    for i in range(len(contours)):\n",
    "        cnt = contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "\n",
    "        if (area > (mask.shape[0] / 20 * mask.shape[1] / 20) and area < (mask.shape[0] * mask.shape[1] * 0.7)):\n",
    "            c_max.append(cnt)\n",
    "    cv2.drawContours(mask_save, c_max, -1, (255), thickness=-1)\n",
    "    if len(c_max) > 0:\n",
    "        box_list=[]\n",
    "        for cnt in c_max:\n",
    "            x, y, w, h = cv2.boundingRect(contours[i])\n",
    "            x1=x\n",
    "            y1=y\n",
    "            x2=x+w\n",
    "            y2=y+h\n",
    "            box_list.append(str(x1)+'_'+str(y1)+'_'+ str(x2)+'_'+str(y2))\n",
    "            content=str(base_name).split('_')\n",
    "#             print(content)\n",
    "            save_name='Tp' +'_'+str(content[4])+'_'+str(content[5])+'_'+str(content[3])+str(content[6])+'_'\n",
    "            for i in range(0,len(box_list)):\n",
    "                 save_name=save_name+box_list[i]+'_'+cls+'_'\n",
    "        cv2.imwrite(probe_dir + save_name.rstrip('_')+ \".png\", img_org)\n",
    "        cv2.imwrite(mask_dir + save_name.rstrip('_') + \".png\", mask_save)\n",
    "        test_name.append(save_name.rstrip('_'))\n",
    "        print('{:d}/{:d} images     {:s}'.format(im_id+1, im_num, save_name.rstrip('_')))\n",
    "    else:\n",
    "        continue\n",
    "    im_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the final testing set catalog file\n",
    "with open('../dataset/casia/test_all_single1.txt', 'w') as f:\n",
    "    for pic in test_name:\n",
    "        test_content = pic.split(\"_\")\n",
    "        if test_content[-1] in cls:\n",
    "            content2 = [str(i) for i in test_content[4:-1]]\n",
    "            content3=' '.join(content2)\n",
    "            f.write('%s %s %s\\n' % (pic,content3,'tamper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“tensor0.12”",
   "language": "python",
   "name": "tensor0.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
